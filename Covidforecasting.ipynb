{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"covid-data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## putting continent as \"new \" for world and international locations\n",
    "for i in df.index:\n",
    "    if(df['location'][i]=='World' or df['location'][i]=='International'):\n",
    "        df['continent'][i]='new'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=34772\n",
    "test=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date']=df['date'].apply(lambda x: pd.Timestamp(x)) # preprocessing dates using pandas library\n",
    "df['date']=df.date.values.astype(np.int64)//(10**9) ## divinding by 10 ^^9 as it is in nano seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_train=df['date'][:train]\n",
    "date_test=df['date'][train:34872]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=df[['new_cases','new_deaths']][:train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=df[['new_cases','new_deaths']][train:34872]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=np.transpose(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=np.transpose(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=np.array(y_train)\n",
    "y_test=np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aravindhant/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/aravindhant/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/Users/aravindhant/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/aravindhant/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "for i in df.index: \n",
    "    if(i!=34872):\n",
    "        if(df['location'][i]!=df['location'][i+1]):\n",
    "            df['total_cases'][i]=0\n",
    "            df['total_deaths'][i]=0\n",
    "            df['new_deaths'][i]=0\n",
    "            df['new_cases'][i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=df[['total_cases','new_cases']].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=df[['total_deaths','new_deaths']].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.replace(np.nan,0,inplace=True)\n",
    "s.replace(np.nan,0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_train=s[:train]\n",
    "t_train=t[:train]\n",
    "s_test=s[train:34872]\n",
    "t_test=t[train:34872]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_train=(date_train,s_train,t_train)\n",
    "x1_test=(date_test,s_test,t_test)\n",
    "x1_train=pd.concat(x1_train,axis=1)\n",
    "x1_test=pd.concat(x1_test,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_train=np.array(x1_train)\n",
    "x1_test=np.array(x1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_train=x1_train.astype(float)\n",
    "x1_test=x1_test.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x1_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_train=np.transpose(x1_train)\n",
    "x1_test=np.transpose(x1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34772"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=df[['continent','location']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "## one hot encoding the continents\n",
    "dummy_variable_1 = pd.get_dummies(g[\"continent\"])\n",
    "dummy_variable_1.astype('float',inplace=True)\n",
    "g = pd.concat([g, dummy_variable_1], axis=1)\n",
    "g.drop('continent',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "## one hot encoding the locations\n",
    "dummy_variable_2 = pd.get_dummies(g[\"location\"])\n",
    "dummy_variable_2.astype('float',inplace=True)\n",
    "g = pd.concat([g, dummy_variable_2], axis=1)\n",
    "g.drop('location',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_train=g[:train]\n",
    "g_test=g[train:34872]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_train=np.array(g_train)\n",
    "g_test=np.array(g_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_train=np.transpose(g_train) ## g is the continent and locations after one hot encoding\n",
    "g_test=np.transpose(g_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "enter name  Albania\n"
     ]
    }
   ],
   "source": [
    "a=input('enter name of location ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=input(' enter date in year-month-date format')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv('covid-data.csv') ## for predicting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1=df1[['continent','location']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in g1.index:\n",
    "    if(g1['location'][i]=='World' or g1['location'][i]=='International'):\n",
    "        g1['continent'][i]='new'\n",
    "\n",
    "for i in g.index:\n",
    "    if(g[a][i]==1):\n",
    "        break\n",
    "loc=g.iloc[i:i+2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc=np.array(loc)\n",
    "loc=np.delete(loc,1,0)\n",
    "loc=np.transpose(loc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df1.index:\n",
    "    if(i!=34872):\n",
    "        if(df1['location'][i]==a):\n",
    "            if(df1['location'][i]!=df1['location'][i+1]):\n",
    "                x1_pred=df1.iloc[[i]]\n",
    "                m=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_pred=x1_pred[['date','total_cases','new_cases','total_deaths','new_deaths']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>total_cases</th>\n",
       "      <th>new_cases</th>\n",
       "      <th>total_deaths</th>\n",
       "      <th>new_deaths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>2020-08-05</td>\n",
       "      <td>5750.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  total_cases  new_cases  total_deaths  new_deaths\n",
       "358  2020-08-05       5750.0      130.0         176.0         4.0"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "date=x1_pred['date'][m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020-08-05'"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=(int(c[5:7])-int(date[5:7]))*30+int(c[8:])-int(date[8:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2020-08-05\n",
       "1   2020-08-06\n",
       "2   2020-08-07\n",
       "3   2020-08-08\n",
       "dtype: datetime64[ns]"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates=pd.Series(pd.date_range(date, periods=p+1, freq=\"d\"))\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1596585600\n",
       "1    1596672000\n",
       "2    1596758400\n",
       "3    1596844800\n",
       "dtype: int64"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates=dates.astype(int)//10**9\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_pred=np.array(x1_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_pred=np.transpose(x1_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 1)\n",
      "(219, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x1_pred.shape)\n",
    "print(loc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_pred[0][0]=dates[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1596672000"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1_pred[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1596672000],\n",
       "       [5750.0],\n",
       "       [130.0],\n",
       "       [176.0],\n",
       "       [4.0]], dtype=object)"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(x1_test,y1_test,parameters1,parameters2):\n",
    "    aL1,caches1 = forward_propagation1(g_test,paramters1)\n",
    "    x2=np.concatenate((aL1,x1_test),axis=0)\n",
    "    aL2,caches2=forward_propagation2(x2,parameters2)\n",
    "    print(\" r2 score for the test data is\", r2_score(aL2,y1_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval(x1_test,y1_test,parameters1,parameters2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x1_pred,dates,loc,parameters1,parameters2): ## predicting for a given day\n",
    "    \n",
    "\n",
    "    for i in range(1,len(dates)):\n",
    "        aL1, caches1 = forward_propagation1(loc, parameters1)\n",
    "        x2=np.concatenate((aL1,x1_pred),axis=0)\n",
    "        aL2,caches2=forward_propagation2(x2,parameters2)\n",
    "        x1_pred[0][0]=dates[i+1]\n",
    "        x1_pred[2][0]=aL2[0][0]##new cases\n",
    "        x1_pred[4][0]=aL2[1][0]##new deaths\n",
    "        x1_pred[1][0]=x1_pred[1][0]+aL2[0][0]##total cases\n",
    "        x1_pred[3][0]=x1_pred[2][0]+aL2[1][0]##total deaths\n",
    "       \n",
    "    # print results\n",
    "    print(\"new cases\",+str(x1_pred[2][0]))\n",
    "    print(\"new deaths\",+str(x1_pred[4][0]))\n",
    "     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('predicted results',+predict(x1_pred,dates,loc,parameters1,parameters2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_dims1=[219,5]##dimension of layers of network1\n",
    "layer_dims2=[10,7,5,2]##dimension of layers of network2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters1,parameters2=model(g_train,x1_train,y_train,layer_dims1,layer_dims2,learning_rate1=0.009,learning_rate2=0.0075,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(g_train, x1_train,y_train, layer_dims1,layer_dims2, learning_rate1 = 0.009,learning_rate2=0.0075, epochs = 100):\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    Arguments:\n",
    "    g -- data(continent and locations one hot encoded), numpy array of shape (219, number of examples)\n",
    "    y_train -- ground truth ( new cases and new deaths)\n",
    "    layers_dims(1,2) -- list containing the input size and each layer size, of length (number of layers + 1).\n",
    "    learning_rate(1,2) -- learning rate of the gradient descent update rule\n",
    "    epochs -- number of iterations for training the model\n",
    "    Returns:\n",
    "    parameters(1,2) -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    costs = []                         # keep track of cost\n",
    "    X=g_train\n",
    "    t=0# counter for adam optimization\n",
    "    # Parameters initialization. (≈ 1 line of code)\n",
    "    ### START CODE HERE ###\n",
    "    parameters1 = initialize_parameters(layer_dims1)\n",
    "    parameters2=initialize_parameters(layer_dims2)\n",
    "    v,s=initialize_adam(parameters2)\n",
    "    ### END CODE HERE ###\n",
    "    # Loop (gradient descent)\n",
    "    for i in range(0, epochs):\n",
    "\n",
    "        \n",
    "        AL1, caches1 = forward_propagation1(X, parameters1) ## forward prop for net1\n",
    "        x2=np.concatenate((AL1,x1_train),axis=0)\n",
    "        AL2,caches2=forward_propagation2(x2,parameters2) ## forward prop for net2\n",
    "        \n",
    "        \n",
    "        # Compute cost.\n",
    "        \n",
    "        cost = compute_cost(AL2, y_train)\n",
    "        \n",
    "    \n",
    "        # Backward propagation for net2\n",
    "        \n",
    "        grads = backward_propagation(x2, y_train, caches2)\n",
    " \n",
    "        # Update parameters.\n",
    "        \n",
    "        #parameters2 = update_parameters2_without_optimization(parameters2, grads, learning_rate)\n",
    "        t=t+1\n",
    "        parameters2,v,s=update_parameters_with_adam(parameters2, grads, v, s, t, learning_rate2,beta1 = 0.9, beta2 = 0.999,  epsilon = 1e-8)\n",
    "        \n",
    "        if(epochs>(epochs//2)):\n",
    "            pass # freezing network 1 after (X epochs out of 2X epochs)\n",
    "        elif(epochs<=(epochs//2)):\n",
    "            parameters1 = update_parameters1(parameters1, grads, learning_rate1)\n",
    "        \n",
    "                \n",
    "        \n",
    "        \n",
    "        \n",
    "        costs.append(cost)\n",
    "            \n",
    "    \n",
    "    \n",
    "    return parameters1,parameters2\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(layer_dims):\n",
    "    np.random.seed(3)\n",
    "    parameters = {}\n",
    "    L = len(layer_dims) # number of layers in the network\n",
    "\n",
    "    for l in range(1, L):\n",
    "        parameters['W' + str(l)] = np.random.randn(layer_dims[l],layer_dims[l-1])*  np.sqrt(2 / (layer_dims[l-1]))\n",
    "        parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n",
    "        assert parameters['W' + str(l)].shape[0] == layer_dims[l], layer_dims[l-1]\n",
    "        assert parameters['W' + str(l)].shape[0] == layer_dims[l], 1\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation1(X,parameters):\n",
    "    caches=[]\n",
    "    a0=X\n",
    "        \n",
    "    z1=np.dot(parameters['W1'],a0)+parameters['b1']\n",
    "    a1=relu(z1)\n",
    "    cache=(a1,parameters['W1'],parameters['b1'],z1)\n",
    "    caches.append(cache)\n",
    "    return a1,caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(Z):\n",
    "    \"\"\"\n",
    "    Implement the RELU function.\n",
    "\n",
    "    Arguments:\n",
    "    Z -- Output of the linear layer, of any shape\n",
    "\n",
    "    Returns:\n",
    "    A -- activation function\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    A = np.maximum(0,Z)\n",
    "    \n",
    "    assert(A.shape == Z.shape)\n",
    "    \n",
    "    \n",
    "    return A\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation2(X,parameters):\n",
    "    a0=X\n",
    "    L=len(parameters)//2\n",
    "    for l in range(1,L):\n",
    "        \n",
    "        Z1=np.dot(parameters['W1'],a0)+parameters['b1']\n",
    "        a1=relu(Z1)\n",
    "        Z2=np.dot(parameters['W2'],a1)+parameters['b2']\n",
    "        a2=relu(Z2)\n",
    "        Z3=np.dot(parameters['W3'],a2)+parameters['b3']\n",
    "        a3=relu(Z3)\n",
    "        cache=(a1,parameters['W1'],parameters['b1'],Z1,a2,parameters['W2'],parameters['b2'],Z2,a3,parameters['W3'],parameters['b3'],Z3)\n",
    "    return a3,cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(AL,Y):\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    Arguments:\n",
    "    AL -- predicted value (vector)\n",
    "    Y -- ground truth\n",
    "\n",
    "    Returns:\n",
    "    cost\n",
    "    \"\"\"\n",
    "    \n",
    "    m = Y.shape[1] #no of examples\n",
    "\n",
    "    # Compute loss from aL and y.\n",
    "    ### START CODE HERE ### (≈ 1 lines of code)\n",
    "    cost =  np.sum((Y-AL)**2)/m\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    cost = np.squeeze(cost)      # To make sure your cost's shape is what we expect \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_backward(dA, cache):\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    Arguments:\n",
    "    dA -- post-activation gradient, of any shape\n",
    "    cache -- 'Z' where we store for computing backward propagation efficiently\n",
    "\n",
    "    Returns:\n",
    "    dZ -- Gradient of the cost with respect to Z\n",
    "    \"\"\"\n",
    "    \n",
    "    Z = cache\n",
    "    dZ = np.array(dA, copy=True) # just converting dz to a correct object.\n",
    "    \n",
    "    # When z <= 0, you should set dz to 0 as well. \n",
    "    dZ[Z <= 0] = 0\n",
    "    \n",
    "    assert (dZ.shape == Z.shape)\n",
    "    \n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(x2,Y,cache):\n",
    "    \n",
    "    \n",
    "    (a1,W1,b1,Z1,a2,W2,b2,Z2,a3,W3,b3,Z3)=cache\n",
    "    dA3 = - 2*(Y-a3)\n",
    "    dz3=relu_backward(dA3,Z3)\n",
    "    m=Y.shape[1]\n",
    "    dW3 = np.dot(dz3, a2.T)/m\n",
    "    db3 = np.sum(dz3, axis=1, keepdims = True)/m\n",
    "    \n",
    "    da2 = np.dot(W3.T, dz3)\n",
    "    dz2 = relu_backward(da2,Z2)\n",
    "    dW2 = np.dot(dz2, a1.T)/m\n",
    "    db2 = np.sum(dz2, axis=1, keepdims = True)/m\n",
    "    \n",
    "    da1 = np.dot(W2.T, dz2)\n",
    "    dz1 = relu_backward(da1,Z1)\n",
    "    dW1 = np.dot(dz1, x2.T)/m\n",
    "    db1 = np.sum(dz1, axis=1, keepdims = True)/m\n",
    "    \n",
    "    gradients = {\"dz3\": dz3, \"dW3\": dW3, \"db3\": db3,\n",
    "                 \"da2\": da2, \"dz2\": dz2, \"dW2\": dW2, \"db2\": db2,\n",
    "                 \"da1\": da1, \"dz1\": dz1, \"dW1\": dW1, \"db1\": db1}\n",
    "    \n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters2_without_optimization(parameters, grads, learning_rate):\n",
    "    \"\"\"\n",
    "    Update parameters using gradient descent\n",
    "    \n",
    "    Arguments:\n",
    "    parameters -- python dictionary containing the  parameters \n",
    "    grads -- python dictionary containing the gradients\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing the updated parameters \n",
    "                  parameters[\"W\" + str(l)] = ... \n",
    "                  parameters[\"b\" + str(l)] = ...\n",
    "    \"\"\"\n",
    "    \n",
    "    L = len(parameters) // 2 # number of layers in the neural network\n",
    "    \n",
    "    # Update rule for each parameter\n",
    "    \n",
    "    for l in range(L):\n",
    "        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - (learning_rate* grads[\"dW\" + str(l + 1)])\n",
    "        parameters[\"b\" + str(l+1)] =  parameters[\"b\" + str(l + 1)] - (learning_rate* grads[\"db\" + str(l+1)])\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OPTIMIZER ADAM\n",
    "def initialize_adam(parameters) :\n",
    "    \"\"\"\n",
    "    Initializes v and s as two python dictionaries with:\n",
    "                - keys: \"dW1\", \"db1\", ..., \"dWL\", \"dbL\" \n",
    "                - values: numpy arrays of zeros of the same shape as the corresponding gradients/parameters.\n",
    "    \n",
    "    Arguments:\n",
    "    parameters -- python dictionary containing your parameters.\n",
    "                    parameters[\"W\" + str(l)] = Wl\n",
    "                    parameters[\"b\" + str(l)] = bl\n",
    "    \n",
    "    Returns: \n",
    "    v -- python dictionary that will contain the exponentially weighted average of the gradient.\n",
    "                    v[\"dW\" + str(l)] = ...\n",
    "                    v[\"db\" + str(l)] = ...\n",
    "    s -- python dictionary that will contain the exponentially weighted average of the squared gradient.\n",
    "                    s[\"dW\" + str(l)] = ...\n",
    "                    s[\"db\" + str(l)] = ...\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    L = len(parameters) // 2 # number of layers in the neural networks\n",
    "    v = {}\n",
    "    s = {}\n",
    "    \n",
    "    # Initialize v, s. Input: \"parameters\". Outputs: \"v, s\".\n",
    "    for l in range(L):\n",
    "    \n",
    "        v[\"dW\" + str(l+1)] = np.zeros((parameters['W' + str(l+1)].shape[0], parameters['W' + str(l+1)].shape[1]))\n",
    "        v[\"db\" + str(l+1)] = np.zeros((parameters['b' + str(l+1)].shape[0], parameters['b' + str(l+1)].shape[1]))\n",
    "        s[\"dW\" + str(l+1)] = np.zeros((parameters['W' + str(l+1)].shape[0], parameters['W' + str(l+1)].shape[1]))\n",
    "        s[\"db\" + str(l+1)] = np.zeros((parameters['b' + str(l+1)].shape[0], parameters['b' + str(l+1)].shape[1]))\n",
    "    \n",
    "    \n",
    "    return v, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UPDATING PARAMETERS WITH ADAM FOR L LAYERS\n",
    "def update_parameters_with_adam(parameters, grads, v, s, t, learning_rate ,\n",
    "                                beta1 = 0.9, beta2 = 0.999,  epsilon = 1e-8):\n",
    "    \"\"\"\n",
    "    Update parameters using Adam\n",
    "    \n",
    "    Arguments:\n",
    "    parameters -- python dictionary containing your parameters:\n",
    "                    parameters['W' + str(l)] = Wl\n",
    "                    parameters['b' + str(l)] = bl\n",
    "    grads -- python dictionary containing your gradients for each parameters:\n",
    "                    grads['dW' + str(l)] = dWl\n",
    "                    grads['db' + str(l)] = dbl\n",
    "    v -- Adam variable, moving average of the first gradient, python dictionary\n",
    "    s -- Adam variable, moving average of the squared gradient, python dictionary\n",
    "    learning_rate -- the learning rate, scalar.\n",
    "    beta1 -- Exponential decay hyperparameter for the first moment estimates \n",
    "    beta2 -- Exponential decay hyperparameter for the second moment estimates \n",
    "    epsilon -- hyperparameter preventing division by zero in Adam updates\n",
    "\n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your updated parameters \n",
    "    v -- Adam variable, moving average of the first gradient, python dictionary\n",
    "    s -- Adam variable, moving average of the squared gradient, python dictionary\n",
    "    \"\"\"\n",
    "    \n",
    "    L = len(parameters) // 2                 # number of layers in the neural networks\n",
    "    v_corrected = {}                         # Initializing first moment estimate, python dictionary\n",
    "    s_corrected = {}                         # Initializing second moment estimate, python dictionary\n",
    "    \n",
    "    # Perform Adam update on all parameters\n",
    "    for l in range(L):\n",
    "        \n",
    "        v[\"dW\" + str(l+1)] = beta1*v[\"dW\" + str(l+1)]+(1-beta1)*grads[\"dW\"+str(l+1)]\n",
    "        v[\"db\" + str(l+1)] = beta1*v[\"db\" + str(l+1)]+(1-beta1)*grads[\"db\"+str(l+1)]\n",
    "        \n",
    "\n",
    "        \n",
    "        v_corrected[\"dW\" + str(l+1)] = v[\"dW\" + str(l+1)]/(1-(beta1**t))\n",
    "        v_corrected[\"db\" + str(l+1)] = v[\"db\" + str(l+1)]/(1-(beta1**t))\n",
    "        \n",
    "        s[\"dW\" + str(l+1)] = beta2*s[\"dW\" + str(l+1)]+(1-beta2)*(grads[\"dW\"+str(l+1)]**2)\n",
    "        s[\"db\" + str(l+1)] = beta2*s[\"db\" + str(l+1)]+(1-beta2)*(grads[\"db\"+str(l+1)]**2)\n",
    "        \n",
    "        s_corrected[\"dW\" + str(l+1)] = s[\"dW\" + str(l+1)]/(1-(beta2**t))\n",
    "        s_corrected[\"db\" + str(l+1)] = s[\"db\" + str(l+1)]/(1-(beta2**t))\n",
    "        \n",
    "        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] -learning_rate*(v_corrected[\"dW\" + str(l+1)]/((np.sqrt(s_corrected[\"dW\" + str(l+1)]) )+epsilon))\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] -learning_rate*(v_corrected[\"db\" + str(l+1)]/((np.sqrt(s_corrected[\"db\" + str(l+1)]) )+epsilon)) \n",
    "        parameters[\"W\" + str(l+1)][np.isnan(parameters[\"W\" + str(l+1)])] = 0\n",
    "        parameters[\"b\" + str(l+1)][np.isnan(parameters[\"b\" + str(l+1)])]=0\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    return parameters, v, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters1(parameters, grads, learning_rate):\n",
    "    \"\"\"\n",
    "    Update parameters using gradient descent\n",
    "    \n",
    "    Arguments:\n",
    "    parameters -- python dictionary containing the parameters \n",
    "    grads -- python dictionary containing your gradients\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing the updated parameters \n",
    "                  parameters[\"W\" + str(l)] = ... \n",
    "                  parameters[\"b\" + str(l)] = ...\n",
    "    \"\"\"\n",
    "    \n",
    "    L = len(parameters) // 2 # number of layers in the neural network\n",
    "    dw=grads['dW1']\n",
    "    dw1=dw[:5,:1]##broadcasting\n",
    "    db=grads['db1']\n",
    "    db1=db[:5,:]\n",
    "    \n",
    "    parameters[\"W\" + str(1)] = parameters[\"W\" + str(1)] - (learning_rate*dW1)\n",
    "    parameters[\"b\" + str(1)] =  parameters[\"b\" + str(1)] - (learning_rate*db1)\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv('covid-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1=df1[['continent','location']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
